# ğŸ“„ PDF RAG API v2.0

Advanced PDF Retrieval-Augmented Generation (RAG) system with FastAPI, ChromaDB, and Groq LLM.

## ğŸŒŸ Features

### Core Features
- âœ… **PDF Processing**: Upload and process PDF documents with intelligent chunking
- âœ… **Vector Search**: Semantic search using sentence transformers and ChromaDB
- âœ… **RAG System**: Question answering with context from uploaded documents
- âœ… **LLM Integration**: Groq API integration with Llama models

### Advanced Features
- ğŸ”§ **Configuration Management**: Pydantic-based settings with environment variables
- ğŸ“Š **Database Integration**: SQLAlchemy async database for metadata and tracking
- ğŸ“ **Professional Logging**: Loguru with rotation and multiple log levels
- ğŸ³ **Dockerized**: Production-ready Docker setup
- ğŸ§ª **Testing**: Comprehensive test suite with pytest
- ğŸ“ˆ **Monitoring**: Built-in statistics and query history
- ğŸ”’ **Security**: Rate limiting and API key support (configurable)
- âš¡ **Performance**: GZip compression and optimized chunking

## ğŸ—ï¸ Architecture

```
fast_api_project/
â”œâ”€â”€ api/                    # API routes
â”‚   â”œâ”€â”€ routes.py          # Main API endpoints
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ config/                 # Configuration
â”‚   â”œâ”€â”€ settings.py        # Pydantic settings
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ db/                     # Database
â”‚   â”œâ”€â”€ database.py        # DB connection
â”‚   â”œâ”€â”€ models.py          # SQLAlchemy models
â”‚   â””â”€â”€ vectordb.py        # Vector DB config
â”œâ”€â”€ models/                 # Pydantic models
â”‚   â””â”€â”€ schemas.py         # Request/Response models
â”œâ”€â”€ services/              # Business logic
â”‚   â”œâ”€â”€ llm_service.py    # LLM integration
â”‚   â”œâ”€â”€ pdf_processor.py  # PDF processing
â”‚   â”œâ”€â”€ vector_service.py # Vector search
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ utils/                 # Utilities
â”‚   â”œâ”€â”€ logger.py         # Logging setup
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ tests/                 # Test suite
â”‚   â”œâ”€â”€ test_api.py       # API tests
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ data/                  # Data directory
â”‚   â”œâ”€â”€ chroma/           # Vector database
â”‚   â””â”€â”€ uploads/          # Uploaded files
â”œâ”€â”€ logs/                  # Log files
â”œâ”€â”€ main.py               # FastAPI app
â”œâ”€â”€ streamlit_app.py      # Streamlit UI
â”œâ”€â”€ requirements.txt      # Dependencies
â”œâ”€â”€ Dockerfile           # Docker image
â”œâ”€â”€ docker-compose.yml   # Docker compose
â””â”€â”€ .env.example        # Environment template
```

## ğŸš€ Quick Start

### Prerequisites
- Python 3.11+
- Docker (optional)
- Groq API Key ([Get it here](https://console.groq.com/))

### Installation

1. **Clone the repository**
```bash
git clone <your-repo>
cd fast_api_project
```

2. **Create virtual environment**
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Configure environment**
```bash
cp .env.example .env
# Edit .env and add your GROQ_API_KEY
```

5. **Run the application**
```bash
python main.py
```

The API will be available at `http://localhost:8000`

### Using Docker

1. **Build and run**
```bash
docker-compose up --build
```

2. **Stop**
```bash
docker-compose down
```

## ğŸ“š API Documentation

Once running, visit:
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

### Key Endpoints

#### ğŸ“¤ Upload PDF
```bash
POST /upload
Content-Type: multipart/form-data

curl -X POST "http://localhost:8000/upload" \
  -F "file=@document.pdf"
```

#### â“ Ask Question
```bash
POST /ask?question=What is this about?&k=5

curl -X POST "http://localhost:8000/ask?question=What%20is%20this%20about&k=5"
```

#### ğŸ“Š Get Statistics
```bash
GET /stats

curl "http://localhost:8000/stats"
```

#### ğŸ“„ List Documents
```bash
GET /documents?limit=50&offset=0

curl "http://localhost:8000/documents"
```

#### ğŸ” Query History
```bash
GET /queries?limit=50&offset=0

curl "http://localhost:8000/queries"
```

#### â¤ï¸ Health Check
```bash
GET /health

curl "http://localhost:8000/health"
```

## ğŸ¨ Streamlit UI

Run the interactive UI:
```bash
streamlit run streamlit_app.py
```

Features:
- Upload PDFs through web interface
- Ask questions with visual feedback
- View document sources
- Adjust search parameters

## ğŸ§ª Testing

Run tests:
```bash
pytest tests/ -v
```

Run with coverage:
```bash
pytest tests/ --cov=. --cov-report=html
```

## âš™ï¸ Configuration

Key environment variables (see `.env.example`):

| Variable | Description | Default |
|----------|-------------|---------|
| `GROQ_API_KEY` | Groq API key | Required |
| `LLM_MODEL` | LLM model name | `llama-3.1-8b-instant` |
| `MAX_FILE_SIZE_MB` | Max upload size | `50` |
| `CHUNK_SIZE_LARGE` | Chunk size for large docs | `800` |
| `DEFAULT_SEARCH_K` | Default search results | `5` |
| `LOG_LEVEL` | Logging level | `INFO` |

## ğŸ“Š Database Schema

### Documents Table
- `doc_id`: Unique document ID
- `filename`: Original filename
- `pdf_hash`: MD5 hash (deduplication)
- `pages`: Number of pages
- `chunks`: Number of text chunks
- `status`: Processing status
- `created_at`: Upload timestamp

### Queries Table
- `question`: User question
- `answer`: LLM response
- `doc_id`: Related document (optional)
- `k_value`: Number of chunks used
- `response_time`: Processing time
- `status`: Query status
- `created_at`: Query timestamp

## ğŸ”§ Advanced Usage

### Custom Chunking Strategy
Edit `services/pdf_processor.py`:
```python
def get_chunk_params(text):
    length = len(text)
    if length < 10_000:
        return 300, 50  # chunk_size, chunk_overlap
    elif length < 50_000:
        return 500, 100
    else:
        return 800, 150
```

### Multiple LLM Models
Edit `config/settings.py`:
```python
LLM_MODEL: str = "llama-3.3-70b-versatile"  # More powerful model
```

### Enable Redis Caching
1. Uncomment Redis service in `docker-compose.yml`
2. Set `USE_CACHE=true` in `.env`

## ğŸ› Troubleshooting

### Common Issues

**1. Import Errors**
```bash
# Make sure all dependencies are installed
pip install -r requirements.txt
```

**2. Database Errors**
```bash
# Delete and recreate database
rm data/app.db
python main.py  # Will auto-create
```

**3. Vector DB Issues**
```bash
# Clear ChromaDB
rm -rf data/chroma/*
```

**4. API Key Errors**
```bash
# Verify GROQ_API_KEY in .env
echo $GROQ_API_KEY
```

## ğŸ“ˆ Performance Tips

1. **Batch Processing**: For multiple PDFs, use async upload
2. **Chunk Size**: Adjust based on document type
3. **Search K**: Start with k=5, increase for better context
4. **Caching**: Enable Redis for frequently asked questions
5. **Database**: Use PostgreSQL for production (update DATABASE_URL)

## ğŸš€ Deployment

### Production Checklist
- [ ] Set `DEBUG=false`
- [ ] Use strong `SECRET_KEY`
- [ ] Enable `ENABLE_API_KEY=true`
- [ ] Configure proper CORS origins
- [ ] Use PostgreSQL instead of SQLite
- [ ] Enable Redis caching
- [ ] Set up reverse proxy (nginx)
- [ ] Configure SSL/TLS
- [ ] Set up monitoring (Prometheus, Grafana)
- [ ] Configure log aggregation

## ğŸ“ License

MIT License

## ğŸ¤ Contributing

Contributions welcome! Please:
1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## ğŸ“§ Support

For issues and questions:
- GitHub Issues
- Documentation: `/docs` endpoint

## ğŸ™ Acknowledgments

- FastAPI
- ChromaDB
- Groq
- Sentence Transformers
- SQLAlchemy

---

Made with â¤ï¸ for better document Q&A
